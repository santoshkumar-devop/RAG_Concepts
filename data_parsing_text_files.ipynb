{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0050da95",
   "metadata": {},
   "source": [
    "# Steps to setup a project\n",
    "\n",
    "1. Create Virtual Environment and swith to virtual environment\n",
    "2. pip install uv\n",
    "3. uv init\n",
    "4. uv add ipykernel, langchain, langchain-community, tqdm, tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a339668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data/text_files\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts={\n",
    "    \"data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"‚úÖ Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a356ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextLoader- Read Single File \n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "## Loading a single text file\n",
    "loader=TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents=loader.load()\n",
    "print(f\"üìÑ Loaded {len(documents)} document\")\n",
    "print(f\"Content preview: {documents[0].page_content[:100]}...\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd85cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DirectoryLoader- Loading  Multiple Text Files\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"data/text_files\",\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=True\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "\n",
    "print(f\"üìÅ Loaded {len(documents)} documents\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Length: {len(doc.page_content)} characters\")\n",
    "\n",
    "\n",
    "# üìä Analysis\n",
    "print(\"\\nüìä DirectoryLoader Characteristics:\")\n",
    "print(\"‚úÖ Advantages:\")\n",
    "print(\"  - Loads multiple files at once\")\n",
    "print(\"  - Supports glob patterns\")\n",
    "print(\"  - Progress tracking\")\n",
    "print(\"  - Recursive directory scanning\")\n",
    "\n",
    "print(\"\\n‚ùå Disadvantages:\")\n",
    "print(\"  - All files must be same type\")\n",
    "print(\"  - Limited error handling per file\")\n",
    "print(\"  - Can be memory intensive for large directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Splitting Strategies\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Method 1: Character-based splitting\n",
    "print(\"1Ô∏è‚É£ CHARACTER TEXT SPLITTER\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",  # Split on newlines\n",
    "    chunk_size=200,  # Max chunk size in characters\n",
    "    chunk_overlap=20,  # Overlap between chunks\n",
    "    length_function=len  # How to measure chunk size\n",
    ")\n",
    "\n",
    "text = documents[0].page_content\n",
    "char_chunks=char_splitter.split_text(text)\n",
    "print(f\"Created {len(char_chunks)} chunks\")\n",
    "print(f\"First chunk: {char_chunks[0][:100]}...\")\n",
    "print(char_chunks[0])\n",
    "print(\"-------------\")\n",
    "print(char_chunks[1])\n",
    "print(\"-------------\")\n",
    "print(char_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e93a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Recursive character splitting (RECOMMENDED)\n",
    "# Text Splitting Strategies\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "print(\"\\n2Ô∏è‚É£ RECURSIVE CHARACTER TEXT SPLITTER\")\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # Try these separators in order\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Created {len(recursive_chunks)} chunks\")\n",
    "print(f\"First chunk: {recursive_chunks[0][:100]}...\")\n",
    "print(recursive_chunks[0])\n",
    "print(\"-----------------\")\n",
    "print(recursive_chunks[1])\n",
    "print(\"------------------\")\n",
    "print(recursive_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Splitting Strategies\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Method 3: Token-based splitting\n",
    "print(\"\\n3Ô∏è‚É£ TOKEN TEXT SPLITTER\")\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50,  # Size in tokens (not characters)\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Created {len(token_chunks)} chunks\")\n",
    "print(f\"First chunk: {token_chunks[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44382f5f",
   "metadata": {},
   "source": [
    "# üìä Comparison\n",
    "print(\"\\nüìä Text Splitting Methods Comparison:\")\n",
    "print(\"\\nCharacterTextSplitter:\")\n",
    "print(\"  ‚úÖ Simple and predictable\")\n",
    "print(\"  ‚úÖ Good for structured text\")\n",
    "print(\"  ‚ùå May break mid-sentence\")\n",
    "print(\"  Use when: Text has clear delimiters\")\n",
    "\n",
    "print(\"\\nRecursiveCharacterTextSplitter:\")\n",
    "print(\"  ‚úÖ Respects text structure\")\n",
    "print(\"  ‚úÖ Tries multiple separators\")\n",
    "print(\"  ‚úÖ Best general-purpose splitter\")\n",
    "print(\"  ‚ùå Slightly more complex\")\n",
    "print(\"  Use when: Default choice for most texts\")\n",
    "\n",
    "print(\"\\nTokenTextSplitter:\")\n",
    "print(\"  ‚úÖ Respects model token limits\")\n",
    "print(\"  ‚úÖ More accurate for embeddings\")\n",
    "print(\"  ‚ùå Slower than character-based\")\n",
    "print(\"  Use when: Working with token-limited models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-concepts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
